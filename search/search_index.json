{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"HTTPX A next-generation HTTP client for Python. Warning This project should be considered as an \"alpha\" release. It is substantially API complete, but there are still some areas that need more work. Let's get started... >>> import httpx >>> r = httpx . get ( 'https://www.example.org/' ) >>> r < Response [ 200 OK ] > >>> r . status_code 200 >>> r . http_version 'HTTP/1.1' >>> r . headers [ 'content-type' ] 'text/html; charset=UTF-8' >>> r . text '<!doctype html> \\n <html> \\n <head> \\n <title>Example Domain</title>...' Features HTTPX builds on the well-established usability of requests , and gives you: A requests-compatible API. HTTP/2 and HTTP/1.1 support. Support for issuing HTTP requests in parallel . (Coming soon) Standard synchronous interface, but with async / await support if you need it . Ability to make requests directly to WSGI or ASGI applications . Strict timeouts everywhere. Fully type annotated. 100% test coverage. Plus all the standard features of requests ... International Domains and URLs Keep-Alive & Connection Pooling Sessions with Cookie Persistence Browser-style SSL Verification Basic/Digest Authentication (Digest is still TODO) Elegant Key/Value Cookies Automatic Decompression Automatic Content Decoding Unicode Response Bodies Multipart File Uploads HTTP(S) Proxy Support (TODO) Connection Timeouts Streaming Downloads .netrc Support Chunked Requests Documentation For a run-through of all the basics, head over to the QuickStart . For more advanced topics, see the Advanced Usage section, or the specific topics on making Parallel Requests or using the Async Client . The Developer Interface provides a comprehensive API reference. Dependencies The HTTPX project relies on these excellent libraries: h2 - HTTP/2 support. h11 - HTTP/1.1 support. certifi - SSL certificates. chardet - Fallback auto-detection for response encoding. hstspreload - determines whether IDNA-encoded host should be only accessed via HTTPS. idna - Internationalized domain name support. rfc3986 - URL parsing & normalization. brotlipy - Decoding for \"brotli\" compressed responses. (Optional) A huge amount of credit is due to requests for the API layout that much of this work follows, as well as to urllib3 for plenty of design inspiration around the lower level networking details. Installation Install with pip: $ pip install httpx HTTPX requires Python 3.6+","title":"Introduction"},{"location":"#features","text":"HTTPX builds on the well-established usability of requests , and gives you: A requests-compatible API. HTTP/2 and HTTP/1.1 support. Support for issuing HTTP requests in parallel . (Coming soon) Standard synchronous interface, but with async / await support if you need it . Ability to make requests directly to WSGI or ASGI applications . Strict timeouts everywhere. Fully type annotated. 100% test coverage. Plus all the standard features of requests ... International Domains and URLs Keep-Alive & Connection Pooling Sessions with Cookie Persistence Browser-style SSL Verification Basic/Digest Authentication (Digest is still TODO) Elegant Key/Value Cookies Automatic Decompression Automatic Content Decoding Unicode Response Bodies Multipart File Uploads HTTP(S) Proxy Support (TODO) Connection Timeouts Streaming Downloads .netrc Support Chunked Requests","title":"Features"},{"location":"#documentation","text":"For a run-through of all the basics, head over to the QuickStart . For more advanced topics, see the Advanced Usage section, or the specific topics on making Parallel Requests or using the Async Client . The Developer Interface provides a comprehensive API reference.","title":"Documentation"},{"location":"#dependencies","text":"The HTTPX project relies on these excellent libraries: h2 - HTTP/2 support. h11 - HTTP/1.1 support. certifi - SSL certificates. chardet - Fallback auto-detection for response encoding. hstspreload - determines whether IDNA-encoded host should be only accessed via HTTPS. idna - Internationalized domain name support. rfc3986 - URL parsing & normalization. brotlipy - Decoding for \"brotli\" compressed responses. (Optional) A huge amount of credit is due to requests for the API layout that much of this work follows, as well as to urllib3 for plenty of design inspiration around the lower level networking details.","title":"Dependencies"},{"location":"#installation","text":"Install with pip: $ pip install httpx HTTPX requires Python 3.6+","title":"Installation"},{"location":"advanced/","text":"Advanced Usage Client Instances Using a Client instance to make requests will give you HTTP connection pooling, will provide cookie persistence, and allows you to apply configuration across all outgoing requests. >>> client = httpx . Client () >>> r = client . get ( 'https://example.org/' ) >>> r < Response [ 200 OK ] > Calling into Python Web Apps You can configure an httpx client to call directly into a Python web application, using either the WSGI or ASGI protocol. This is particularly useful for two main use-cases: Using httpx as a client, inside test cases. Mocking out external services, during tests or in dev/staging environments. Here's an example of integrating against a Flask application: from flask import Flask import httpx app = Flask ( __name__ ) @app.route ( \"/\" ) def hello (): return \"Hello World!\" client = httpx . Client ( app = app ) r = client . get ( 'http://example/' ) assert r . status_code == 200 assert r . text == \"Hello World!\" For some more complex cases you might need to customize the WSGI or ASGI dispatch. This allows you to: Inspect 500 error responses, rather than raise exceptions, by setting raise_app_exceptions=False . Mount the WSGI or ASGI application at a subpath, by setting script_name (WSGI) or root_path (ASGI). Use a given the client address for requests, by setting remote_addr (WSGI) or client (ASGI). For example: # Instantiate a client that makes WSGI requests with a client IP of \"1.2.3.4\". dispatch = httpx . WSGIDispatch ( app = app , remote_addr = \"1.2.3.4\" ) client = httpx . Client ( dispatch = dispatch ) Build Request You can use Client.build_request() to build a request and make modifications before sending the request. >>> client = httpx . Client () >>> req = client . build_request ( \"OPTIONS\" , \"https://example.com\" ) >>> req . url . full_path = \"*\" # Build an 'OPTIONS *' request for CORS >>> client . send ( r ) < Response [ 200 OK ] > Specify the version of HTTP protocol One can set the version of HTTP protocol for the client in case you want to make the requests using specific version. For example: h11_client = httpx . Client ( http_versions = [ \"HTTP/1.1\" ]) h11_response = h11_client . get ( \"https://myserver.com\" ) h2_client = httpx . Client ( http_versions = [ \"HTTP/2\" ]) h2_response = h2_client . get ( \"https://myserver.com\" ) .netrc Support HTTPX supports .netrc file. In trust_env=True cases, if auth parameter is not defined, HTTPX tries to add auth into request's header from .netrc file. As default trust_env is true. To set false: >>> httpx . get ( 'https://example.org/' , trust_env = False ) If NETRC environment is empty, HTTPX tries to use default files. ( ~/.netrc , ~/_netrc ) To change NETRC environment: >>> import os >>> os . environ [ \"NETRC\" ] = \"my_default_folder/.my_netrc\" .netrc file content example: machine netrcexample . org login example - username password example - password ... HTTP Proxying HTTPX supports setting up proxies the same way that Requests does via the proxies parameter. For example to forward all HTTP traffic to http://127.0.0.1:3080 and all HTTPS traffic to http://127.0.0.1:3081 your proxies config would look like this: >>> client = httpx . Client ( proxies = { \"http\" : \"http://127.0.0.1:3080\" , \"https\" : \"http://127.0.0.1:3081\" }) Proxies can be configured for a specific scheme and host, all schemes of a host, all hosts for a scheme, or for all requests. When determining which proxy configuration to use for a given request this same order is used. >>> client = httpx . Client ( proxies = { \"http://example.com\" : \"...\" , # Host+Scheme \"all://example.com\" : \"...\" , # Host \"http\" : \"...\" , # Scheme \"all\" : \"...\" , # All }) >>> client = httpx . Client ( proxies = \"...\" ) # Shortcut for 'all' Warning To make sure that proxies cannot read your traffic, and even if the proxy_url uses HTTPS, it is recommended to use HTTPS and tunnel requests if possible. By default HTTPProxy will operate as a forwarding proxy for http://... requests and will establish a CONNECT TCP tunnel for https:// requests. This doesn't change regardless of the proxy_url being http or https . Proxies can be configured to have different behavior such as forwarding or tunneling all requests: proxy = httpx . HTTPProxy ( proxy_url = \"https://127.0.0.1\" , proxy_mode = httpx . HTTPProxyMode . TUNNEL_ONLY ) client = httpx . Client ( proxies = proxy ) # This request will be tunnelled instead of forwarded. client . get ( \"http://example.com\" )","title":"Advanced Usage"},{"location":"advanced/#advanced-usage","text":"","title":"Advanced Usage"},{"location":"advanced/#client-instances","text":"Using a Client instance to make requests will give you HTTP connection pooling, will provide cookie persistence, and allows you to apply configuration across all outgoing requests. >>> client = httpx . Client () >>> r = client . get ( 'https://example.org/' ) >>> r < Response [ 200 OK ] >","title":"Client Instances"},{"location":"advanced/#calling-into-python-web-apps","text":"You can configure an httpx client to call directly into a Python web application, using either the WSGI or ASGI protocol. This is particularly useful for two main use-cases: Using httpx as a client, inside test cases. Mocking out external services, during tests or in dev/staging environments. Here's an example of integrating against a Flask application: from flask import Flask import httpx app = Flask ( __name__ ) @app.route ( \"/\" ) def hello (): return \"Hello World!\" client = httpx . Client ( app = app ) r = client . get ( 'http://example/' ) assert r . status_code == 200 assert r . text == \"Hello World!\" For some more complex cases you might need to customize the WSGI or ASGI dispatch. This allows you to: Inspect 500 error responses, rather than raise exceptions, by setting raise_app_exceptions=False . Mount the WSGI or ASGI application at a subpath, by setting script_name (WSGI) or root_path (ASGI). Use a given the client address for requests, by setting remote_addr (WSGI) or client (ASGI). For example: # Instantiate a client that makes WSGI requests with a client IP of \"1.2.3.4\". dispatch = httpx . WSGIDispatch ( app = app , remote_addr = \"1.2.3.4\" ) client = httpx . Client ( dispatch = dispatch )","title":"Calling into Python Web Apps"},{"location":"advanced/#build-request","text":"You can use Client.build_request() to build a request and make modifications before sending the request. >>> client = httpx . Client () >>> req = client . build_request ( \"OPTIONS\" , \"https://example.com\" ) >>> req . url . full_path = \"*\" # Build an 'OPTIONS *' request for CORS >>> client . send ( r ) < Response [ 200 OK ] >","title":"Build Request"},{"location":"advanced/#specify-the-version-of-http-protocol","text":"One can set the version of HTTP protocol for the client in case you want to make the requests using specific version. For example: h11_client = httpx . Client ( http_versions = [ \"HTTP/1.1\" ]) h11_response = h11_client . get ( \"https://myserver.com\" ) h2_client = httpx . Client ( http_versions = [ \"HTTP/2\" ]) h2_response = h2_client . get ( \"https://myserver.com\" )","title":"Specify the version of HTTP protocol"},{"location":"advanced/#netrc-support","text":"HTTPX supports .netrc file. In trust_env=True cases, if auth parameter is not defined, HTTPX tries to add auth into request's header from .netrc file. As default trust_env is true. To set false: >>> httpx . get ( 'https://example.org/' , trust_env = False ) If NETRC environment is empty, HTTPX tries to use default files. ( ~/.netrc , ~/_netrc ) To change NETRC environment: >>> import os >>> os . environ [ \"NETRC\" ] = \"my_default_folder/.my_netrc\" .netrc file content example: machine netrcexample . org login example - username password example - password ...","title":".netrc Support"},{"location":"advanced/#http-proxying","text":"HTTPX supports setting up proxies the same way that Requests does via the proxies parameter. For example to forward all HTTP traffic to http://127.0.0.1:3080 and all HTTPS traffic to http://127.0.0.1:3081 your proxies config would look like this: >>> client = httpx . Client ( proxies = { \"http\" : \"http://127.0.0.1:3080\" , \"https\" : \"http://127.0.0.1:3081\" }) Proxies can be configured for a specific scheme and host, all schemes of a host, all hosts for a scheme, or for all requests. When determining which proxy configuration to use for a given request this same order is used. >>> client = httpx . Client ( proxies = { \"http://example.com\" : \"...\" , # Host+Scheme \"all://example.com\" : \"...\" , # Host \"http\" : \"...\" , # Scheme \"all\" : \"...\" , # All }) >>> client = httpx . Client ( proxies = \"...\" ) # Shortcut for 'all' Warning To make sure that proxies cannot read your traffic, and even if the proxy_url uses HTTPS, it is recommended to use HTTPS and tunnel requests if possible. By default HTTPProxy will operate as a forwarding proxy for http://... requests and will establish a CONNECT TCP tunnel for https:// requests. This doesn't change regardless of the proxy_url being http or https . Proxies can be configured to have different behavior such as forwarding or tunneling all requests: proxy = httpx . HTTPProxy ( proxy_url = \"https://127.0.0.1\" , proxy_mode = httpx . HTTPProxyMode . TUNNEL_ONLY ) client = httpx . Client ( proxies = proxy ) # This request will be tunnelled instead of forwarded. client . get ( \"http://example.com\" )","title":"HTTP Proxying"},{"location":"api/","text":"Developer Interface Helper Functions Note Only use these functions if you're testing HTTPX in a console or making a small number of requests. Using a Client will enable HTTP/2 and connection pooling for more efficient and long-lived connections. get(url, [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) options(url, [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) head(url, [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) post(url, [data], [json], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) put(url, [data], [json], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) patch(url, [data], [json], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) delete(url, [data], [json], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) request(method, url, [data], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) build_request(method, url, [data], [files], [json], [params], [headers], [cookies]) Client An HTTP client, with connection pooling, HTTP/2, redirects, cookie persistence, etc. >>> client = httpx . Client () >>> response = client . get ( 'https://example.org' ) def __init__([auth], [headers], [cookies], [verify], [cert], [timeout], [pool_limits], [max_redirects], [app], [dispatch]) .headers - Headers .cookies - Cookies def .get(url, [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) def .options(url, [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) def .head(url, [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) def .post(url, [data], [json], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) def .put(url, [data], [json], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) def .patch(url, [data], [json], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) def .delete(url, [data], [json], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) def .request(method, url, [data], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) def .build_request(method, url, [data], [files], [json], [params], [headers], [cookies]) def .send(request, [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) def .close() Response An HTTP response. def __init__(...) .status_code - int .reason_phrase - str .http_version - \"HTTP/2\" or \"HTTP/1.1\" .url - URL .headers - Headers .content - bytes .text - str .encoding - str .is_redirect - bool .request - Request .cookies - Cookies .history - List[Response] .elapsed - timedelta The amount of time elapsed between sending the first byte and parsing the headers (not including time spent reading the response). Use total_seconds() to correctly get the total elapsed seconds. def .raise_for_status() - None def .json() - Any def .read() - bytes def .stream() - bytes iterator def .raw() - bytes iterator def .close() - None def .next() - Response Request An HTTP request. Can be constructed explicitly for more control over exactly what gets sent over the wire. >>> request = httpx . Request ( \"GET\" , \"https://example.org\" , headers = { 'host' : 'example.org' }) >>> response = client . send ( request ) def __init__(method, url, [params], [data], [json], [headers], [cookies]) .method - str .url - URL .content - byte or byte async iterator .headers - Headers .cookies - Cookies URL A normalized, IDNA supporting URL. >>> url = URL ( \"https://example.org/\" ) >>> url . host 'example.org' def __init__(url, allow_relative=False, params=None) .scheme - str .authority - str .host - str .port - int .path - str .query - str .full_path - str .fragment - str .is_ssl - bool .origin - Origin .is_absolute_url - bool .is_relative_url - bool def .copy_with([scheme], [authority], [path], [query], [fragment]) - URL def .resolve_with(url) - URL Origin A normalized, IDNA supporting set of scheme/host/port info. >>> Origin ( 'https://example.org' ) == Origin ( 'HTTPS://EXAMPLE.ORG:443' ) True def __init__(url) .scheme - str .is_ssl - bool .host - str .port - int Headers A case-insensitive multi-dict. >>> headers = Headers ({ 'Content-Type' : 'application/json' }) >>> headers [ 'content-type' ] 'application/json' def __init__(self, headers) Cookies A dict-like cookie store. >>> cookies = Cookies () >>> cookies . set ( \"name\" , \"value\" , domain = \"example.org\" ) def __init__(cookies: [dict, Cookies, CookieJar]) .jar - CookieJar def extract_cookies(response) def set_cookie_header(request) def set(name, value, [domain], [path]) def get(name, [domain], [path]) def delete(name, [domain], [path]) def clear([domain], [path]) Standard mutable mapping interface","title":"Developer Interface"},{"location":"api/#developer-interface","text":"","title":"Developer Interface"},{"location":"api/#helper-functions","text":"Note Only use these functions if you're testing HTTPX in a console or making a small number of requests. Using a Client will enable HTTP/2 and connection pooling for more efficient and long-lived connections. get(url, [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) options(url, [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) head(url, [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) post(url, [data], [json], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) put(url, [data], [json], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) patch(url, [data], [json], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) delete(url, [data], [json], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) request(method, url, [data], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) build_request(method, url, [data], [files], [json], [params], [headers], [cookies])","title":"Helper Functions"},{"location":"api/#client","text":"An HTTP client, with connection pooling, HTTP/2, redirects, cookie persistence, etc. >>> client = httpx . Client () >>> response = client . get ( 'https://example.org' ) def __init__([auth], [headers], [cookies], [verify], [cert], [timeout], [pool_limits], [max_redirects], [app], [dispatch]) .headers - Headers .cookies - Cookies def .get(url, [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) def .options(url, [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) def .head(url, [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) def .post(url, [data], [json], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) def .put(url, [data], [json], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) def .patch(url, [data], [json], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) def .delete(url, [data], [json], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) def .request(method, url, [data], [params], [headers], [cookies], [auth], [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) def .build_request(method, url, [data], [files], [json], [params], [headers], [cookies]) def .send(request, [stream], [allow_redirects], [verify], [cert], [timeout], [proxies]) def .close()","title":"Client"},{"location":"api/#response","text":"An HTTP response. def __init__(...) .status_code - int .reason_phrase - str .http_version - \"HTTP/2\" or \"HTTP/1.1\" .url - URL .headers - Headers .content - bytes .text - str .encoding - str .is_redirect - bool .request - Request .cookies - Cookies .history - List[Response] .elapsed - timedelta The amount of time elapsed between sending the first byte and parsing the headers (not including time spent reading the response). Use total_seconds() to correctly get the total elapsed seconds. def .raise_for_status() - None def .json() - Any def .read() - bytes def .stream() - bytes iterator def .raw() - bytes iterator def .close() - None def .next() - Response","title":"Response"},{"location":"api/#request","text":"An HTTP request. Can be constructed explicitly for more control over exactly what gets sent over the wire. >>> request = httpx . Request ( \"GET\" , \"https://example.org\" , headers = { 'host' : 'example.org' }) >>> response = client . send ( request ) def __init__(method, url, [params], [data], [json], [headers], [cookies]) .method - str .url - URL .content - byte or byte async iterator .headers - Headers .cookies - Cookies","title":"Request"},{"location":"api/#url","text":"A normalized, IDNA supporting URL. >>> url = URL ( \"https://example.org/\" ) >>> url . host 'example.org' def __init__(url, allow_relative=False, params=None) .scheme - str .authority - str .host - str .port - int .path - str .query - str .full_path - str .fragment - str .is_ssl - bool .origin - Origin .is_absolute_url - bool .is_relative_url - bool def .copy_with([scheme], [authority], [path], [query], [fragment]) - URL def .resolve_with(url) - URL","title":"URL"},{"location":"api/#origin","text":"A normalized, IDNA supporting set of scheme/host/port info. >>> Origin ( 'https://example.org' ) == Origin ( 'HTTPS://EXAMPLE.ORG:443' ) True def __init__(url) .scheme - str .is_ssl - bool .host - str .port - int","title":"Origin"},{"location":"api/#headers","text":"A case-insensitive multi-dict. >>> headers = Headers ({ 'Content-Type' : 'application/json' }) >>> headers [ 'content-type' ] 'application/json' def __init__(self, headers)","title":"Headers"},{"location":"api/#cookies","text":"A dict-like cookie store. >>> cookies = Cookies () >>> cookies . set ( \"name\" , \"value\" , domain = \"example.org\" ) def __init__(cookies: [dict, Cookies, CookieJar]) .jar - CookieJar def extract_cookies(response) def set_cookie_header(request) def set(name, value, [domain], [path]) def get(name, [domain], [path]) def delete(name, [domain], [path]) def clear([domain], [path]) Standard mutable mapping interface","title":"Cookies"},{"location":"async/","text":"Async Client HTTPX offers a standard synchronous API by default, but also gives you the option of an async client if you need it. Async is a concurrency model that is far more efficient than multi-threading, and can provide significant performance benefits and enable the use of long-lived network connections such as WebSockets. If you're working with an async web framework then you'll also want to use an async client for sending outgoing HTTP requests. Making Async requests To make asynchronous requests, you'll need an AsyncClient . >>> async with httpx . AsyncClient () as client : >>> r = await client . get ( 'https://www.example.com/' ) >>> r < Response [ 200 OK ] > Tip Use IPython to try this code interactively, as it supports executing async / await expressions in the console. Note The async with syntax ensures that all active connections are closed on exit. It is safe to access response content (e.g. r.text ) both inside and outside the async with block, unless you are using response streaming. In that case, you should .read() , .stream() , or .close() the response inside the async with block. API Differences If you're using streaming responses then there are a few bits of API that use async methods: >>> async with httpx . AsyncClient () as client : >>> r = await client . get ( 'https://www.example.com/' , stream = True ) >>> async for chunk in r . stream (): >>> ... The async response methods are: .read() .stream() .raw() .close() If you're making parallel requests , then you'll also need to use an async API: >>> async with httpx . AsyncClient () as client : >>> async with client . parallel () as parallel : >>> pending_one = parallel . get ( 'https://example.com/1' ) >>> pending_two = parallel . get ( 'https://example.com/2' ) >>> response_one = await pending_one . get_response () >>> response_two = await pending_two . get_response () The async parallel methods are: .parallel() Used as an \"async with\" context manager. .get_response() .next_response()","title":"Async Client"},{"location":"async/#async-client","text":"HTTPX offers a standard synchronous API by default, but also gives you the option of an async client if you need it. Async is a concurrency model that is far more efficient than multi-threading, and can provide significant performance benefits and enable the use of long-lived network connections such as WebSockets. If you're working with an async web framework then you'll also want to use an async client for sending outgoing HTTP requests.","title":"Async Client"},{"location":"async/#making-async-requests","text":"To make asynchronous requests, you'll need an AsyncClient . >>> async with httpx . AsyncClient () as client : >>> r = await client . get ( 'https://www.example.com/' ) >>> r < Response [ 200 OK ] > Tip Use IPython to try this code interactively, as it supports executing async / await expressions in the console. Note The async with syntax ensures that all active connections are closed on exit. It is safe to access response content (e.g. r.text ) both inside and outside the async with block, unless you are using response streaming. In that case, you should .read() , .stream() , or .close() the response inside the async with block.","title":"Making Async requests"},{"location":"async/#api-differences","text":"If you're using streaming responses then there are a few bits of API that use async methods: >>> async with httpx . AsyncClient () as client : >>> r = await client . get ( 'https://www.example.com/' , stream = True ) >>> async for chunk in r . stream (): >>> ... The async response methods are: .read() .stream() .raw() .close() If you're making parallel requests , then you'll also need to use an async API: >>> async with httpx . AsyncClient () as client : >>> async with client . parallel () as parallel : >>> pending_one = parallel . get ( 'https://example.com/1' ) >>> pending_two = parallel . get ( 'https://example.com/2' ) >>> response_one = await pending_one . get_response () >>> response_two = await pending_two . get_response () The async parallel methods are: .parallel() Used as an \"async with\" context manager. .get_response() .next_response()","title":"API Differences"},{"location":"compatibility/","text":"Requests Compatibility Guide HTTPX aims to be compatible with the requests API wherever possible. This documentation outlines places where the API differs... QuickStart Pretty much all the API mentioned in the requests QuickStart should be identical to the API in our own documentation. The following exceptions apply: Response.url - Returns a URL instance, rather than a string. Use str(response.url) if you need a string instance. httpx.codes - In our documentation we prefer the uppercased versions, such as codes.NOT_FOUND , but also provide lower-cased versions for API compatibility with requests . stream=True . - Streaming responses provide the .stream() and .raw() byte iterator interfaces, rather than the .iter_content() method and the .raw socket interface. Advanced Usage Warning TODO","title":"Requests Compatibility"},{"location":"compatibility/#requests-compatibility-guide","text":"HTTPX aims to be compatible with the requests API wherever possible. This documentation outlines places where the API differs...","title":"Requests Compatibility Guide"},{"location":"compatibility/#quickstart","text":"Pretty much all the API mentioned in the requests QuickStart should be identical to the API in our own documentation. The following exceptions apply: Response.url - Returns a URL instance, rather than a string. Use str(response.url) if you need a string instance. httpx.codes - In our documentation we prefer the uppercased versions, such as codes.NOT_FOUND , but also provide lower-cased versions for API compatibility with requests . stream=True . - Streaming responses provide the .stream() and .raw() byte iterator interfaces, rather than the .iter_content() method and the .raw socket interface.","title":"QuickStart"},{"location":"compatibility/#advanced-usage","text":"Warning TODO","title":"Advanced Usage"},{"location":"contributing/","text":"Contributing Thank you for being interested in contributing with HTTPX. There are many ways you can contribute with the project: Try HTTPX and report bugs/issues you find Implement new features Review Pull Requests of others Write documentation Participate in discussions Reporting Bugs or Other Issues Found something that HTTPX should support? Stumbled upon some unexpected behavior? Feel free to open an issue at the issue tracker . Try to be more descriptive as you can and in case of a bug report, provide as much information as possible like: OS platform Python version Installed dependencies and versions ( python -m pip freeze ) Code snippet Error traceback Development To start developing HTTPX create a fork of the HTTPX repository on GitHub. Then clone your fork with the following command replacing YOUR-USERNAME with your GitHub username: $ git clone https://github.com/YOUR-USERNAME/httpx With the repository cloned you can access its folder, set up the virtual environment, install the project requirements, and then install HTTPX on edit mode: $ cd httpx $ python3 -m venv venv $ source venv/bin/activate $ pip install -r test-requirements.txt $ pip install -e . Note Feel free to replace this step with your development environment setup (pyenv, pipenv, virtualenvwrapper, docker, etc). Testing and Linting We use nox to automate testing, linting, and documentation building workflow. Make sure you have it installed at your system before starting. Install nox with: $ python3 -m pip install --user nox Alternatively, use pipx if you prefer to keep it into an isolated environment: $ pipx install nox Now, with nox installed run the complete pipeline with: $ nox Warning The test suite spawns a testing server at the port 8000 . Make sure this isn't being used, so the tests can run properly. To run the code auto-formatting separately: $ nox -s lint Also, if you need to run the tests only: $ nox -s test You can also run a single test script like this: $ nox -s test -- tests/test_multipart.py Documenting To work with the documentation, make sure you have mkdocs and mkdocs-material installed on your environment: $ pip install mkdocs mkdocs-material To spawn the docs server run: $ mkdocs serve","title":"Contributing"},{"location":"contributing/#contributing","text":"Thank you for being interested in contributing with HTTPX. There are many ways you can contribute with the project: Try HTTPX and report bugs/issues you find Implement new features Review Pull Requests of others Write documentation Participate in discussions","title":"Contributing"},{"location":"contributing/#reporting-bugs-or-other-issues","text":"Found something that HTTPX should support? Stumbled upon some unexpected behavior? Feel free to open an issue at the issue tracker . Try to be more descriptive as you can and in case of a bug report, provide as much information as possible like: OS platform Python version Installed dependencies and versions ( python -m pip freeze ) Code snippet Error traceback","title":"Reporting Bugs or Other Issues"},{"location":"contributing/#development","text":"To start developing HTTPX create a fork of the HTTPX repository on GitHub. Then clone your fork with the following command replacing YOUR-USERNAME with your GitHub username: $ git clone https://github.com/YOUR-USERNAME/httpx With the repository cloned you can access its folder, set up the virtual environment, install the project requirements, and then install HTTPX on edit mode: $ cd httpx $ python3 -m venv venv $ source venv/bin/activate $ pip install -r test-requirements.txt $ pip install -e . Note Feel free to replace this step with your development environment setup (pyenv, pipenv, virtualenvwrapper, docker, etc).","title":"Development"},{"location":"contributing/#testing-and-linting","text":"We use nox to automate testing, linting, and documentation building workflow. Make sure you have it installed at your system before starting. Install nox with: $ python3 -m pip install --user nox Alternatively, use pipx if you prefer to keep it into an isolated environment: $ pipx install nox Now, with nox installed run the complete pipeline with: $ nox Warning The test suite spawns a testing server at the port 8000 . Make sure this isn't being used, so the tests can run properly. To run the code auto-formatting separately: $ nox -s lint Also, if you need to run the tests only: $ nox -s test You can also run a single test script like this: $ nox -s test -- tests/test_multipart.py","title":"Testing and Linting"},{"location":"contributing/#documenting","text":"To work with the documentation, make sure you have mkdocs and mkdocs-material installed on your environment: $ pip install mkdocs mkdocs-material To spawn the docs server run: $ mkdocs serve","title":"Documenting"},{"location":"environment_variables/","text":"Environment Variables The HTTPX library can be configured via environment variables. Here is a list of environment variables that HTTPX recognizes and what function they serve: HTTPX_DEBUG Valid values: 1 , true If this environment variable is set to a valid value then low-level details about the execution of HTTP requests will be logged to stderr . This can help you debug issues and see what's exactly being sent over the wire and to which location. Example: # test_script.py import httpx client = httpx . Client () client . get ( \"https://google.com\" ) user@host:~$ HTTPX_DEBUG = 1 python test_script.py 20:54:17.585 - httpx.dispatch.connection_pool - acquire_connection origin=Origin(scheme='https' host='www.google.com' port=443) 20:54:17.585 - httpx.dispatch.connection_pool - new_connection connection=HTTPConnection(origin=Origin(scheme='https' host='www.google.com' port=443)) 20:54:17.590 - httpx.dispatch.connection - start_connect host='www.google.com' port=443 timeout=TimeoutConfig(timeout=5.0) 20:54:17.651 - httpx.dispatch.connection - connected http_version='HTTP/2' 20:54:17.651 - httpx.dispatch.http2 - send_headers stream_id=1 headers=[(b':method', b'GET'), (b':authority', b'www.google.com'), ...] 20:54:17.652 - httpx.dispatch.http2 - end_stream stream_id=1 20:54:17.681 - httpx.dispatch.http2 - receive_event stream_id=0 event=<RemoteSettingsChanged changed_settings:{...}> 20:54:17.681 - httpx.dispatch.http2 - receive_event stream_id=0 event=<WindowUpdated stream_id:0, delta:983041> 20:54:17.682 - httpx.dispatch.http2 - receive_event stream_id=0 event=<SettingsAcknowledged changed_settings:{}> 20:54:17.739 - httpx.dispatch.http2 - receive_event stream_id=1 event=<ResponseReceived stream_id:1, headers:[(b':status', b'200'), ...]> 20:54:17.741 - httpx.dispatch.http2 - receive_event stream_id=1 event=<DataReceived stream_id:1, flow_controlled_length:5224 data:> 20:54:17.742 - httpx.dispatch.http2 - receive_event stream_id=1 event=<DataReceived stream_id:1, flow_controlled_length:59, data:> 20:54:17.742 - httpx.dispatch.http2 - receive_event stream_id=1 event=<StreamEnded stream_id:1> 20:54:17.742 - httpx.dispatch.http2 - receive_event stream_id=0 event=<PingReceived ping_data:0000000000000000> 20:54:17.743 - httpx.dispatch.connection_pool - release_connection connection=HTTPConnection(origin=Origin(scheme='https' host='www.google.com' port=443)) SSLKEYLOGFILE Valid values: a filename If this environment variable is set, TLS keys will be appended to the specified file, creating it if it doesn't exist, whenever key material is generated or received. The keylog file is designed for debugging purposes only. Support for SSLKEYLOGFILE requires Python 3.8 and OpenSSL 1.1.1 or newer. Example: # test_script.py import httpx client = httpx . Client () client . get ( \"https://google.com\" ) SSLKEYLOGFILE=test.log python test_script.py cat test.log # TLS secrets log file, generated by OpenSSL / Python SERVER_HANDSHAKE_TRAFFIC_SECRET XXXX EXPORTER_SECRET XXXX SERVER_TRAFFIC_SECRET_0 XXXX CLIENT_HANDSHAKE_TRAFFIC_SECRET XXXX CLIENT_TRAFFIC_SECRET_0 XXXX SERVER_HANDSHAKE_TRAFFIC_SECRET XXXX EXPORTER_SECRET XXXX SERVER_TRAFFIC_SECRET_0 XXXX CLIENT_HANDSHAKE_TRAFFIC_SECRET XXXX CLIENT_TRAFFIC_SECRET_0 XXXX HTTP_PROXY , HTTPS_PROXY , ALL_PROXY Valid values: A URL to a proxy Sets the proxy to be used for http , https , or all requests respectively. export HTTP_PROXY = http://127.0.0.1:3080 # This request will be sent through the proxy python -c \"import httpx; httpx.get('http://example.com')\"","title":"Environment Variables"},{"location":"environment_variables/#environment-variables","text":"The HTTPX library can be configured via environment variables. Here is a list of environment variables that HTTPX recognizes and what function they serve:","title":"Environment Variables"},{"location":"environment_variables/#httpx_debug","text":"Valid values: 1 , true If this environment variable is set to a valid value then low-level details about the execution of HTTP requests will be logged to stderr . This can help you debug issues and see what's exactly being sent over the wire and to which location. Example: # test_script.py import httpx client = httpx . Client () client . get ( \"https://google.com\" ) user@host:~$ HTTPX_DEBUG = 1 python test_script.py 20:54:17.585 - httpx.dispatch.connection_pool - acquire_connection origin=Origin(scheme='https' host='www.google.com' port=443) 20:54:17.585 - httpx.dispatch.connection_pool - new_connection connection=HTTPConnection(origin=Origin(scheme='https' host='www.google.com' port=443)) 20:54:17.590 - httpx.dispatch.connection - start_connect host='www.google.com' port=443 timeout=TimeoutConfig(timeout=5.0) 20:54:17.651 - httpx.dispatch.connection - connected http_version='HTTP/2' 20:54:17.651 - httpx.dispatch.http2 - send_headers stream_id=1 headers=[(b':method', b'GET'), (b':authority', b'www.google.com'), ...] 20:54:17.652 - httpx.dispatch.http2 - end_stream stream_id=1 20:54:17.681 - httpx.dispatch.http2 - receive_event stream_id=0 event=<RemoteSettingsChanged changed_settings:{...}> 20:54:17.681 - httpx.dispatch.http2 - receive_event stream_id=0 event=<WindowUpdated stream_id:0, delta:983041> 20:54:17.682 - httpx.dispatch.http2 - receive_event stream_id=0 event=<SettingsAcknowledged changed_settings:{}> 20:54:17.739 - httpx.dispatch.http2 - receive_event stream_id=1 event=<ResponseReceived stream_id:1, headers:[(b':status', b'200'), ...]> 20:54:17.741 - httpx.dispatch.http2 - receive_event stream_id=1 event=<DataReceived stream_id:1, flow_controlled_length:5224 data:> 20:54:17.742 - httpx.dispatch.http2 - receive_event stream_id=1 event=<DataReceived stream_id:1, flow_controlled_length:59, data:> 20:54:17.742 - httpx.dispatch.http2 - receive_event stream_id=1 event=<StreamEnded stream_id:1> 20:54:17.742 - httpx.dispatch.http2 - receive_event stream_id=0 event=<PingReceived ping_data:0000000000000000> 20:54:17.743 - httpx.dispatch.connection_pool - release_connection connection=HTTPConnection(origin=Origin(scheme='https' host='www.google.com' port=443))","title":"HTTPX_DEBUG"},{"location":"environment_variables/#sslkeylogfile","text":"Valid values: a filename If this environment variable is set, TLS keys will be appended to the specified file, creating it if it doesn't exist, whenever key material is generated or received. The keylog file is designed for debugging purposes only. Support for SSLKEYLOGFILE requires Python 3.8 and OpenSSL 1.1.1 or newer. Example: # test_script.py import httpx client = httpx . Client () client . get ( \"https://google.com\" ) SSLKEYLOGFILE=test.log python test_script.py cat test.log # TLS secrets log file, generated by OpenSSL / Python SERVER_HANDSHAKE_TRAFFIC_SECRET XXXX EXPORTER_SECRET XXXX SERVER_TRAFFIC_SECRET_0 XXXX CLIENT_HANDSHAKE_TRAFFIC_SECRET XXXX CLIENT_TRAFFIC_SECRET_0 XXXX SERVER_HANDSHAKE_TRAFFIC_SECRET XXXX EXPORTER_SECRET XXXX SERVER_TRAFFIC_SECRET_0 XXXX CLIENT_HANDSHAKE_TRAFFIC_SECRET XXXX CLIENT_TRAFFIC_SECRET_0 XXXX","title":"SSLKEYLOGFILE"},{"location":"environment_variables/#http_proxy-https_proxy-all_proxy","text":"Valid values: A URL to a proxy Sets the proxy to be used for http , https , or all requests respectively. export HTTP_PROXY = http://127.0.0.1:3080 # This request will be sent through the proxy python -c \"import httpx; httpx.get('http://example.com')\"","title":"HTTP_PROXY, HTTPS_PROXY, ALL_PROXY"},{"location":"parallel/","text":"Parallel Requests Warning This page documents some proposed functionality that is not yet released. See pull request #52 for the first-pass of an implementation. HTTPX allows you to make HTTP requests in parallel in a highly efficient way, using async under the hood, while still presenting a standard threaded interface. This has the huge benefit of allowing you to efficiently make parallel HTTP requests without having to switch out to using async all the way through. Making Parallel Requests Let's make two outgoing HTTP requests in parallel: >>> with httpx . parallel () as parallel : >>> pending_one = parallel . get ( 'https://example.com/1' ) >>> pending_two = parallel . get ( 'https://example.com/2' ) >>> response_one = pending_one . get_response () >>> response_two = pending_two . get_response () If we're making lots of outgoing requests, we might not want to deal with the responses sequentially, but rather deal with each response that comes back as soon as it's available: >>> with httpx . parallel () as parallel : >>> for counter in range ( 1 , 10 ): >>> parallel . get ( f 'https://example.com/{counter}' ) >>> while parallel . has_pending_responses : >>> r = parallel . next_response () Exceptions and Cancellations The style of using parallel blocks ensures that you'll always have well defined exception and cancellation behaviours. Request exceptions are only ever raised when calling either get_response or next_response , and any pending requests are cancelled on exiting the block. Parallel requests with a Client You can also call parallel() from a client instance, which allows you to control the authentication or dispatch behaviour for all requests within the block. >>> client = httpx . Client () >>> with client . parallel () as parallel : >>> ... Async parallel requests If you're working within an async framework, then you'll want to use a fully async API for making requests. >>> client = httpx . AsyncClient () >>> async with client . parallel () as parallel : >>> pending_one = await parallel . get ( 'https://example.com/1' ) >>> pending_two = await parallel . get ( 'https://example.com/2' ) >>> response_one = await pending_one . get_response () >>> response_two = await pending_two . get_response () See the Async Client documentation for more details.","title":"Parallel Requests"},{"location":"parallel/#parallel-requests","text":"Warning This page documents some proposed functionality that is not yet released. See pull request #52 for the first-pass of an implementation. HTTPX allows you to make HTTP requests in parallel in a highly efficient way, using async under the hood, while still presenting a standard threaded interface. This has the huge benefit of allowing you to efficiently make parallel HTTP requests without having to switch out to using async all the way through.","title":"Parallel Requests"},{"location":"parallel/#making-parallel-requests","text":"Let's make two outgoing HTTP requests in parallel: >>> with httpx . parallel () as parallel : >>> pending_one = parallel . get ( 'https://example.com/1' ) >>> pending_two = parallel . get ( 'https://example.com/2' ) >>> response_one = pending_one . get_response () >>> response_two = pending_two . get_response () If we're making lots of outgoing requests, we might not want to deal with the responses sequentially, but rather deal with each response that comes back as soon as it's available: >>> with httpx . parallel () as parallel : >>> for counter in range ( 1 , 10 ): >>> parallel . get ( f 'https://example.com/{counter}' ) >>> while parallel . has_pending_responses : >>> r = parallel . next_response ()","title":"Making Parallel Requests"},{"location":"parallel/#exceptions-and-cancellations","text":"The style of using parallel blocks ensures that you'll always have well defined exception and cancellation behaviours. Request exceptions are only ever raised when calling either get_response or next_response , and any pending requests are cancelled on exiting the block.","title":"Exceptions and Cancellations"},{"location":"parallel/#parallel-requests-with-a-client","text":"You can also call parallel() from a client instance, which allows you to control the authentication or dispatch behaviour for all requests within the block. >>> client = httpx . Client () >>> with client . parallel () as parallel : >>> ...","title":"Parallel requests with a Client"},{"location":"parallel/#async-parallel-requests","text":"If you're working within an async framework, then you'll want to use a fully async API for making requests. >>> client = httpx . AsyncClient () >>> async with client . parallel () as parallel : >>> pending_one = await parallel . get ( 'https://example.com/1' ) >>> pending_two = await parallel . get ( 'https://example.com/2' ) >>> response_one = await pending_one . get_response () >>> response_two = await pending_two . get_response () See the Async Client documentation for more details.","title":"Async parallel requests"},{"location":"quickstart/","text":"QuickStart Note This page closely follows the layout of the requests QuickStart documentation. The httpx library is designed to be API compatible with requests wherever possible. First start by importing HTTPX: >>> import httpx Now, let\u2019s try to get a webpage. >>> r = httpx . get ( 'https://httpbin.org/get' ) >>> r < Response [ 200 OK ] > Similarly, to make an HTTP POST request: >>> r = httpx . post ( 'https://httpbin.org/post' , data = { 'key' : 'value' }) The PUT, DELETE, HEAD, and OPTIONS requests all follow the same style: >>> r = httpx . put ( 'https://httpbin.org/put' , data = { 'key' : 'value' }) >>> r = httpx . delete ( 'https://httpbin.org/delete' ) >>> r = httpx . head ( 'https://httpbin.org/get' ) >>> r = httpx . options ( 'https://httpbin.org/get' ) Passing Parameters in URLs To include URL query parameters in the request, use the params keyword: >>> params = { 'key1' : 'value1' , 'key2' : 'value2' } >>> r = httpx . get ( 'https://httpbin.org/get' , params = params ) To see how the values get encoding into the URL string, we can inspect the resulting URL that was used to make the request: >>> r . url URL ( 'https://httpbin.org/get?key2=value2&key1=value1' ) You can also pass a list of items as a value: >>> params = { 'key1' : 'value1' , 'key2' : [ 'value2' , 'value3' ]} >>> r = httpx . get ( 'https://httpbin.org/get' , params = params ) >>> r . url URL ( 'https://httpbin.org/get?key1=value1&key2=value2&key2=value3' ) Response Content HTTPX will automatically handle decoding the response content into unicode text. >>> r = httpx . get ( 'https://www.example.org/' ) >>> r . text '<!doctype html> \\n <html> \\n <head> \\n <title>Example Domain</title>...' You can inspect what encoding has been used to decode the response. >>> r . encoding 'UTF-8' If you need to override the standard behavior and explicitly set the encoding to use, then you can do that too. >>> r . encoding = 'ISO-8859-1' Binary Response Content The response content can also be accessed as bytes, for non-text responses: >>> r . content b '<!doctype html> \\n <html> \\n <head> \\n <title>Example Domain</title>...' Any gzip and deflate HTTP response encodings will automatically be decoded for you. If brotlipy is installed, then the brotli response encoding will also be supported. For example, to create an image from binary data returned by a request, you can use the following code: >>> from PIL import Image >>> from io import BytesIO >>> i = Image . open ( BytesIO ( r . content )) JSON Response Content Often Web API responses will be encoded as JSON. >>> r = httpx . get ( 'https://api.github.com/events' ) >>> r . json () [{ u 'repository' : { u 'open_issues' : 0 , u 'url' : 'https://github.com/...' ... }}] Custom Headers To include additional headers in the outgoing request, use the headers keyword argument: >>> url = 'http://httpbin.org/headers' >>> headers = { 'user-agent' : 'my-app/0.0.1' } >>> r = httpx . get ( url , headers = headers ) Sending Form Encoded Data Some types of HTTP requests, such as POST and PUT requests, can include data in the request body. One common way of including that is as form encoded data, which is used for HTML forms. >>> data = { 'key1' : 'value1' , 'key2' : 'value2' } >>> r = httpx . post ( \"https://httpbin.org/post\" , data = data ) >>> print ( r . text ) { ... \"form\" : { \"key2\" : \"value2\" , \"key1\" : \"value1\" }, ... } Form encoded data can also include multiple values form a given key. >>> data = { 'key1' : [ 'value1' , 'value2' ]} >>> r = httpx . post ( \"https://httpbin.org/post\" , data = data ) >>> print ( r . text ) { ... \"form\" : { \"key1\" : [ \"value1\" , \"value2\" ] }, ... } Sending Multipart File Uploads You can also upload files, using HTTP multipart encoding: >>> files = { 'upload-file' : open ( 'report.xls' , 'rb' )} >>> r = httpx . post ( \"https://httpbin.org/post\" , files = files ) >>> print ( r . text ) { ... \"files\" : { \"upload-file\" : \"<... binary content ...>\" }, ... } You can also explicitly set the filename and content type, by using a tuple of items for the file value: >>> files = { 'upload-file' : ( 'report.xls' , open ( 'report.xls' , 'rb' ), 'application/vnd.ms-excel' )} >>> r = httpx . post ( \"https://httpbin.org/post\" , files = files ) >>> print ( r . text ) { ... \"files\" : { \"upload-file\" : \"<... binary content ...>\" }, ... } Sending JSON Encoded Data Form encoded data is okay if all you need is simple key-value data structure. For more complicated data structures you'll often want to use JSON encoding instead. >>> data = { 'integer' : 123 , 'boolean' : True , 'list' : [ 'a' , 'b' , 'c' ]} >>> r = httpx . post ( \"https://httpbin.org/post\" , json = data ) >>> print ( r . text ) { ... \"json\" : { \"boolean\" : true , \"integer\" : 123 , \"list\" : [ \"a\" , \"b\" , \"c\" ] }, ... } Sending Binary Request Data For other encodings you should use either a bytes type, or a generator that yields bytes . You'll probably also want to set a custom Content-Type header when uploading binary data. Response Status Codes We can inspect the HTTP status code of the response: >>> r = httpx . get ( 'https://httpbin.org/get' ) >>> r . status_code 200 HTTPX also includes an easy shortcut for accessing status codes by their text phrase. >>> r . status_code == httpx . codes . OK True We can raise an exception for any Client or Server error responses (4xx or 5xx status codes): >>> not_found = httpx . get ( 'https://httpbin.org/status/404' ) >>> not_found . status_code 404 >>> not_found . raise_for_status () Traceback ( most recent call last ): File \"/Users/tomchristie/GitHub/encode/httpcore/httpx/models.py\" , line 776 , in raise_for_status raise HttpError ( message ) httpx . exceptions . HttpError : 404 Not Found Any successful response codes will simply return None rather than raising an exception. >>> r . raise_for_status () Response Headers The response headers are available as a dictionary-like interface. >>> r . headers Headers ({ 'content-encoding' : 'gzip' , 'transfer-encoding' : 'chunked' , 'connection' : 'close' , 'server' : 'nginx/1.0.4' , 'x-runtime' : '148ms' , 'etag' : '\"e1ca502697e5c9317743dc078f67693f\"' , 'content-type' : 'application/json' }) The Headers data type is case-insensitive, so you can use any capitalization. >>> r . headers [ 'Content-Type' ] 'application/json' >>> r . headers . get ( 'content-type' ) 'application/json' Multiple values for a single response header are represented as a single comma separated value, as per RFC 7230 : A recipient MAY combine multiple header fields with the same field name into one \u201cfield-name: field-value\u201d pair, without changing the semantics of the message, by appending each subsequent field value to the combined field value in order, separated by a comma. Cookies Any cookies that are set on the response can be easily accessed: >>> r = httpx . get ( 'http://httpbin.org/cookies/set?chocolate=chip' , allow_redirects = False ) >>> r . cookies [ 'chocolate' ] 'chip' To include cookies in an outgoing request, use the cookies parameter: >>> cookies = { \"peanut\" : \"butter\" } >>> r = httpx . get ( 'http://httpbin.org/cookies' , cookies = cookies ) >>> r . json () { 'cookies' : { 'peanut' : 'butter' }} Cookies are returned in a Cookies instance, which is a dict-like data structure with additional API for accessing cookies by their domain or path. >>> cookies = httpx . Cookies () >>> cookies . set ( 'cookie_on_domain' , 'hello, there!' , domain = 'httpbin.org' ) >>> cookies . set ( 'cookie_off_domain' , 'nope.' , domain = 'example.org' ) >>> r = httpx . get ( 'http://httpbin.org/cookies' , cookies = cookies ) >>> r . json () { 'cookies' : { 'cookie_on_domain' : 'hello, there!' }} Redirection and History By default HTTPX will follow redirects for anything except HEAD requests. The history property of the response can be used to inspect any followed redirects. It contains a list of all any redirect responses that were followed, in the order in which they were made. For example, GitHub redirects all HTTP requests to HTTPS. >>> r = httpx . get ( 'http://github.com/' ) >>> r . url URL ( 'https://github.com/' ) >>> r . status_code 200 >>> r . history [ < Response [ 301 Moved Permanently ] > ] You can modify the default redirection handling with the allow_redirects parameter: >>> r = httpx . get ( 'http://github.com/' , allow_redirects = False ) >>> r . status_code 301 >>> r . history [] If you\u2019re making a HEAD request, you can use this to enable redirection: >>> r = httpx . head ( 'http://github.com/' , allow_redirects = True ) >>> r . url 'https://github.com/' >>> r . history [ < Response [ 301 Moved Permanently ] > ] Timeouts HTTPX defaults to including reasonable timeouts for all network operations, meaning that if a connection is not properly established then it should always raise an error rather than hanging indefinitely. The default timeout for network inactivity is five seconds. You can modify the value to be more or less strict: >>> httpx . get ( 'https://github.com/' , timeout = 0.001 ) Authentication HTTPX supports Basic and Digest HTTP authentication. To provide Basic authentication credentials, pass a 2-tuple of plaintext str or bytes objects as the auth argument to the request functions: >>> httpx . get ( \"https://example.com\" , auth = ( \"my_user\" , \"password123\" )) To provide credentials for Digest authentication you'll need to instantiate a DigestAuth object with the plaintext username and password as arguments. This object can be then passed as the auth argument to the request methods as above: ```python auth = httpx.DigestAuth(\"my_user\", \"password123\") httpx.get(\"https://example.com\", auth=auth)","title":"QuickStart"},{"location":"quickstart/#quickstart","text":"Note This page closely follows the layout of the requests QuickStart documentation. The httpx library is designed to be API compatible with requests wherever possible. First start by importing HTTPX: >>> import httpx Now, let\u2019s try to get a webpage. >>> r = httpx . get ( 'https://httpbin.org/get' ) >>> r < Response [ 200 OK ] > Similarly, to make an HTTP POST request: >>> r = httpx . post ( 'https://httpbin.org/post' , data = { 'key' : 'value' }) The PUT, DELETE, HEAD, and OPTIONS requests all follow the same style: >>> r = httpx . put ( 'https://httpbin.org/put' , data = { 'key' : 'value' }) >>> r = httpx . delete ( 'https://httpbin.org/delete' ) >>> r = httpx . head ( 'https://httpbin.org/get' ) >>> r = httpx . options ( 'https://httpbin.org/get' )","title":"QuickStart"},{"location":"quickstart/#passing-parameters-in-urls","text":"To include URL query parameters in the request, use the params keyword: >>> params = { 'key1' : 'value1' , 'key2' : 'value2' } >>> r = httpx . get ( 'https://httpbin.org/get' , params = params ) To see how the values get encoding into the URL string, we can inspect the resulting URL that was used to make the request: >>> r . url URL ( 'https://httpbin.org/get?key2=value2&key1=value1' ) You can also pass a list of items as a value: >>> params = { 'key1' : 'value1' , 'key2' : [ 'value2' , 'value3' ]} >>> r = httpx . get ( 'https://httpbin.org/get' , params = params ) >>> r . url URL ( 'https://httpbin.org/get?key1=value1&key2=value2&key2=value3' )","title":"Passing Parameters in URLs"},{"location":"quickstart/#response-content","text":"HTTPX will automatically handle decoding the response content into unicode text. >>> r = httpx . get ( 'https://www.example.org/' ) >>> r . text '<!doctype html> \\n <html> \\n <head> \\n <title>Example Domain</title>...' You can inspect what encoding has been used to decode the response. >>> r . encoding 'UTF-8' If you need to override the standard behavior and explicitly set the encoding to use, then you can do that too. >>> r . encoding = 'ISO-8859-1'","title":"Response Content"},{"location":"quickstart/#binary-response-content","text":"The response content can also be accessed as bytes, for non-text responses: >>> r . content b '<!doctype html> \\n <html> \\n <head> \\n <title>Example Domain</title>...' Any gzip and deflate HTTP response encodings will automatically be decoded for you. If brotlipy is installed, then the brotli response encoding will also be supported. For example, to create an image from binary data returned by a request, you can use the following code: >>> from PIL import Image >>> from io import BytesIO >>> i = Image . open ( BytesIO ( r . content ))","title":"Binary Response Content"},{"location":"quickstart/#json-response-content","text":"Often Web API responses will be encoded as JSON. >>> r = httpx . get ( 'https://api.github.com/events' ) >>> r . json () [{ u 'repository' : { u 'open_issues' : 0 , u 'url' : 'https://github.com/...' ... }}]","title":"JSON Response Content"},{"location":"quickstart/#custom-headers","text":"To include additional headers in the outgoing request, use the headers keyword argument: >>> url = 'http://httpbin.org/headers' >>> headers = { 'user-agent' : 'my-app/0.0.1' } >>> r = httpx . get ( url , headers = headers )","title":"Custom Headers"},{"location":"quickstart/#sending-form-encoded-data","text":"Some types of HTTP requests, such as POST and PUT requests, can include data in the request body. One common way of including that is as form encoded data, which is used for HTML forms. >>> data = { 'key1' : 'value1' , 'key2' : 'value2' } >>> r = httpx . post ( \"https://httpbin.org/post\" , data = data ) >>> print ( r . text ) { ... \"form\" : { \"key2\" : \"value2\" , \"key1\" : \"value1\" }, ... } Form encoded data can also include multiple values form a given key. >>> data = { 'key1' : [ 'value1' , 'value2' ]} >>> r = httpx . post ( \"https://httpbin.org/post\" , data = data ) >>> print ( r . text ) { ... \"form\" : { \"key1\" : [ \"value1\" , \"value2\" ] }, ... }","title":"Sending Form Encoded Data"},{"location":"quickstart/#sending-multipart-file-uploads","text":"You can also upload files, using HTTP multipart encoding: >>> files = { 'upload-file' : open ( 'report.xls' , 'rb' )} >>> r = httpx . post ( \"https://httpbin.org/post\" , files = files ) >>> print ( r . text ) { ... \"files\" : { \"upload-file\" : \"<... binary content ...>\" }, ... } You can also explicitly set the filename and content type, by using a tuple of items for the file value: >>> files = { 'upload-file' : ( 'report.xls' , open ( 'report.xls' , 'rb' ), 'application/vnd.ms-excel' )} >>> r = httpx . post ( \"https://httpbin.org/post\" , files = files ) >>> print ( r . text ) { ... \"files\" : { \"upload-file\" : \"<... binary content ...>\" }, ... }","title":"Sending Multipart File Uploads"},{"location":"quickstart/#sending-json-encoded-data","text":"Form encoded data is okay if all you need is simple key-value data structure. For more complicated data structures you'll often want to use JSON encoding instead. >>> data = { 'integer' : 123 , 'boolean' : True , 'list' : [ 'a' , 'b' , 'c' ]} >>> r = httpx . post ( \"https://httpbin.org/post\" , json = data ) >>> print ( r . text ) { ... \"json\" : { \"boolean\" : true , \"integer\" : 123 , \"list\" : [ \"a\" , \"b\" , \"c\" ] }, ... }","title":"Sending JSON Encoded Data"},{"location":"quickstart/#sending-binary-request-data","text":"For other encodings you should use either a bytes type, or a generator that yields bytes . You'll probably also want to set a custom Content-Type header when uploading binary data.","title":"Sending Binary Request Data"},{"location":"quickstart/#response-status-codes","text":"We can inspect the HTTP status code of the response: >>> r = httpx . get ( 'https://httpbin.org/get' ) >>> r . status_code 200 HTTPX also includes an easy shortcut for accessing status codes by their text phrase. >>> r . status_code == httpx . codes . OK True We can raise an exception for any Client or Server error responses (4xx or 5xx status codes): >>> not_found = httpx . get ( 'https://httpbin.org/status/404' ) >>> not_found . status_code 404 >>> not_found . raise_for_status () Traceback ( most recent call last ): File \"/Users/tomchristie/GitHub/encode/httpcore/httpx/models.py\" , line 776 , in raise_for_status raise HttpError ( message ) httpx . exceptions . HttpError : 404 Not Found Any successful response codes will simply return None rather than raising an exception. >>> r . raise_for_status ()","title":"Response Status Codes"},{"location":"quickstart/#response-headers","text":"The response headers are available as a dictionary-like interface. >>> r . headers Headers ({ 'content-encoding' : 'gzip' , 'transfer-encoding' : 'chunked' , 'connection' : 'close' , 'server' : 'nginx/1.0.4' , 'x-runtime' : '148ms' , 'etag' : '\"e1ca502697e5c9317743dc078f67693f\"' , 'content-type' : 'application/json' }) The Headers data type is case-insensitive, so you can use any capitalization. >>> r . headers [ 'Content-Type' ] 'application/json' >>> r . headers . get ( 'content-type' ) 'application/json' Multiple values for a single response header are represented as a single comma separated value, as per RFC 7230 : A recipient MAY combine multiple header fields with the same field name into one \u201cfield-name: field-value\u201d pair, without changing the semantics of the message, by appending each subsequent field value to the combined field value in order, separated by a comma.","title":"Response Headers"},{"location":"quickstart/#cookies","text":"Any cookies that are set on the response can be easily accessed: >>> r = httpx . get ( 'http://httpbin.org/cookies/set?chocolate=chip' , allow_redirects = False ) >>> r . cookies [ 'chocolate' ] 'chip' To include cookies in an outgoing request, use the cookies parameter: >>> cookies = { \"peanut\" : \"butter\" } >>> r = httpx . get ( 'http://httpbin.org/cookies' , cookies = cookies ) >>> r . json () { 'cookies' : { 'peanut' : 'butter' }} Cookies are returned in a Cookies instance, which is a dict-like data structure with additional API for accessing cookies by their domain or path. >>> cookies = httpx . Cookies () >>> cookies . set ( 'cookie_on_domain' , 'hello, there!' , domain = 'httpbin.org' ) >>> cookies . set ( 'cookie_off_domain' , 'nope.' , domain = 'example.org' ) >>> r = httpx . get ( 'http://httpbin.org/cookies' , cookies = cookies ) >>> r . json () { 'cookies' : { 'cookie_on_domain' : 'hello, there!' }}","title":"Cookies"},{"location":"quickstart/#redirection-and-history","text":"By default HTTPX will follow redirects for anything except HEAD requests. The history property of the response can be used to inspect any followed redirects. It contains a list of all any redirect responses that were followed, in the order in which they were made. For example, GitHub redirects all HTTP requests to HTTPS. >>> r = httpx . get ( 'http://github.com/' ) >>> r . url URL ( 'https://github.com/' ) >>> r . status_code 200 >>> r . history [ < Response [ 301 Moved Permanently ] > ] You can modify the default redirection handling with the allow_redirects parameter: >>> r = httpx . get ( 'http://github.com/' , allow_redirects = False ) >>> r . status_code 301 >>> r . history [] If you\u2019re making a HEAD request, you can use this to enable redirection: >>> r = httpx . head ( 'http://github.com/' , allow_redirects = True ) >>> r . url 'https://github.com/' >>> r . history [ < Response [ 301 Moved Permanently ] > ]","title":"Redirection and History"},{"location":"quickstart/#timeouts","text":"HTTPX defaults to including reasonable timeouts for all network operations, meaning that if a connection is not properly established then it should always raise an error rather than hanging indefinitely. The default timeout for network inactivity is five seconds. You can modify the value to be more or less strict: >>> httpx . get ( 'https://github.com/' , timeout = 0.001 )","title":"Timeouts"},{"location":"quickstart/#authentication","text":"HTTPX supports Basic and Digest HTTP authentication. To provide Basic authentication credentials, pass a 2-tuple of plaintext str or bytes objects as the auth argument to the request functions: >>> httpx . get ( \"https://example.com\" , auth = ( \"my_user\" , \"password123\" )) To provide credentials for Digest authentication you'll need to instantiate a DigestAuth object with the plaintext username and password as arguments. This object can be then passed as the auth argument to the request methods as above: ```python auth = httpx.DigestAuth(\"my_user\", \"password123\") httpx.get(\"https://example.com\", auth=auth)","title":"Authentication"}]}